{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d019c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930b58c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from embeddings.dataloader import TheDataSet\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorboard\n",
    "# from tensorboard import SummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87f3d2ac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoder_training_epochs = 150\n",
    "# dataset_file = 'data_ae_train/fulldata.npy'\n",
    "# dataset_file = 'data/fulldata.npy'\n",
    "dataset_file = 'data/autoencoder_fulldata.npy'\n",
    "# dataset_file = 'data/autoencoder_fulldata_mini.npy'\n",
    "\n",
    "# dataset_file = 'data/labdata.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97497e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mxxx = np.load(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3edc7161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54871, 1338), 1.0, 0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxxx.shape, np.max(mxxx), np.min(mxxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c92ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del mxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f92fc52",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "# writer = SummaryWriter(f\"runs/autoencoder_experiment_{encoder_training_epochs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4748a102",
   "metadata": {},
   "source": [
    "## AutoEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c8c4b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting embeddings/autoencoder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile embeddings/autoencoder.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=num_features, out_features=num_features // 2 , bias=True),\n",
    "            nn.Dropout(p = 0.1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=num_features // 2, out_features=128, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=128, out_features=64, bias=True),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=64, out_features=128, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=128, out_features=num_features // 2, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=num_features // 2, out_features=num_features, bias=True ),\n",
    "            #nn.Sigmoid()\n",
    "            nn.Tanh()\n",
    "#             nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81beaed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting embeddings/autoencoder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile embeddings/autoencoder.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=num_features, out_features=128 , bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=128, out_features=64, bias=True),\n",
    "            nn.Tanh(),\n",
    "#             nn.Linear(in_features=64, out_features=32, bias=True),\n",
    "#             nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "#             nn.Linear(in_features=32, out_features=64, bias=True),\n",
    "#             nn.Tanh(),\n",
    "            nn.Linear(in_features=64, out_features=128, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=128, out_features=num_features, bias=True ),\n",
    "            #nn.Sigmoid()\n",
    "            nn.Tanh()\n",
    "#             nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7125f318",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from embeddings.autoencoder import Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ae3d8",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e48a5f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, num_epochs=5, batch_size=64, learning_rate=1e-3):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    torch.manual_seed(42)\n",
    "    criterion = nn.MSELoss() # mean square error loss\n",
    "#     criterion = nn.L1Loss()\n",
    "#     criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=learning_rate, \n",
    "                                 weight_decay=1e-5) # <--\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    outputs = []\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_loader:\n",
    "            X = X.to(device)\n",
    "            recon = model(X.float())\n",
    "            loss = criterion(recon, X.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
    "        losses.append(float(loss))\n",
    "#         writer.add_scalar(f'training loss {num_epochs}',\n",
    "#                             loss,\n",
    "#                             epoch * len(train_loader))\n",
    "        # stop training if loss is low\n",
    "        if loss < 0.0050:\n",
    "            break\n",
    "    return outputs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91acd673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset length = 54871 num features = 1337\n",
      "Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=1337, out_features=668, bias=True)\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "    (2): Tanh()\n",
      "    (3): Linear(in_features=668, out_features=128, bias=True)\n",
      "    (4): Tanh()\n",
      "    (5): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (6): Tanh()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=128, out_features=668, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=668, out_features=1337, bias=True)\n",
      "    (5): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dataset = TheDataSet(datafile=dataset_file, pad_to_360=False)\n",
    "print(f\"dataset length = {len(dataset)} num features = {dataset.num_features()}\")\n",
    "model = Autoencoder(num_features=dataset.num_features())\n",
    "print(model)\n",
    "max_epochs = encoder_training_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c06dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:0.0458\n",
      "Epoch:2, Loss:0.0325\n",
      "Epoch:3, Loss:0.0282\n",
      "Epoch:4, Loss:0.0262\n",
      "Epoch:5, Loss:0.0245\n",
      "Epoch:6, Loss:0.0225\n",
      "Epoch:7, Loss:0.0211\n",
      "Epoch:8, Loss:0.0191\n",
      "Epoch:9, Loss:0.0194\n",
      "Epoch:10, Loss:0.0192\n",
      "Epoch:11, Loss:0.0190\n",
      "Epoch:12, Loss:0.0184\n",
      "Epoch:13, Loss:0.0164\n",
      "Epoch:14, Loss:0.0169\n",
      "Epoch:15, Loss:0.0160\n",
      "Epoch:16, Loss:0.0159\n",
      "Epoch:17, Loss:0.0162\n",
      "Epoch:18, Loss:0.0159\n",
      "Epoch:19, Loss:0.0158\n",
      "Epoch:20, Loss:0.0145\n",
      "Epoch:21, Loss:0.0151\n",
      "Epoch:22, Loss:0.0129\n",
      "Epoch:23, Loss:0.0149\n",
      "Epoch:24, Loss:0.0165\n",
      "Epoch:25, Loss:0.0149\n",
      "Epoch:26, Loss:0.0153\n",
      "Epoch:27, Loss:0.0147\n",
      "Epoch:28, Loss:0.0143\n",
      "Epoch:29, Loss:0.0152\n",
      "Epoch:30, Loss:0.0144\n",
      "Epoch:31, Loss:0.0133\n",
      "Epoch:32, Loss:0.0141\n",
      "Epoch:33, Loss:0.0137\n",
      "Epoch:34, Loss:0.0158\n",
      "Epoch:35, Loss:0.0147\n",
      "Epoch:36, Loss:0.0141\n",
      "Epoch:37, Loss:0.0155\n",
      "Epoch:38, Loss:0.0135\n",
      "Epoch:39, Loss:0.0143\n",
      "Epoch:40, Loss:0.0144\n",
      "Epoch:41, Loss:0.0132\n",
      "Epoch:42, Loss:0.0144\n",
      "Epoch:43, Loss:0.0142\n",
      "Epoch:44, Loss:0.0137\n",
      "Epoch:45, Loss:0.0140\n",
      "Epoch:46, Loss:0.0152\n",
      "Epoch:47, Loss:0.0140\n",
      "Epoch:48, Loss:0.0125\n",
      "Epoch:49, Loss:0.0144\n",
      "Epoch:50, Loss:0.0129\n",
      "Epoch:51, Loss:0.0145\n",
      "Epoch:52, Loss:0.0137\n",
      "Epoch:53, Loss:0.0130\n",
      "Epoch:54, Loss:0.0137\n",
      "Epoch:55, Loss:0.0131\n",
      "Epoch:56, Loss:0.0126\n",
      "Epoch:57, Loss:0.0132\n",
      "Epoch:58, Loss:0.0141\n",
      "Epoch:59, Loss:0.0124\n",
      "Epoch:60, Loss:0.0147\n",
      "Epoch:61, Loss:0.0126\n",
      "Epoch:62, Loss:0.0131\n",
      "Epoch:63, Loss:0.0128\n",
      "Epoch:64, Loss:0.0130\n",
      "Epoch:65, Loss:0.0125\n",
      "Epoch:66, Loss:0.0139\n",
      "Epoch:67, Loss:0.0137\n",
      "Epoch:68, Loss:0.0124\n",
      "Epoch:69, Loss:0.0140\n",
      "Epoch:70, Loss:0.0126\n",
      "Epoch:71, Loss:0.0127\n",
      "Epoch:72, Loss:0.0139\n",
      "Epoch:73, Loss:0.0136\n",
      "Epoch:74, Loss:0.0128\n",
      "Epoch:75, Loss:0.0113\n",
      "Epoch:76, Loss:0.0115\n",
      "Epoch:77, Loss:0.0115\n",
      "Epoch:78, Loss:0.0129\n",
      "Epoch:79, Loss:0.0120\n",
      "Epoch:80, Loss:0.0134\n",
      "Epoch:81, Loss:0.0148\n",
      "Epoch:82, Loss:0.0125\n",
      "Epoch:83, Loss:0.0108\n",
      "Epoch:84, Loss:0.0117\n",
      "Epoch:85, Loss:0.0116\n",
      "Epoch:86, Loss:0.0122\n",
      "Epoch:87, Loss:0.0105\n",
      "Epoch:88, Loss:0.0128\n",
      "Epoch:89, Loss:0.0134\n",
      "Epoch:90, Loss:0.0125\n",
      "Epoch:91, Loss:0.0134\n",
      "Epoch:92, Loss:0.0122\n",
      "Epoch:93, Loss:0.0141\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs, losses = train(model, dataset=dataset, num_epochs=max_epochs, batch_size = 512, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aadd68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "# x = np.linspace(0, 10, 1000)\n",
    "ax.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "05b93076",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dataset = TheDataSet(datafile='data/fulldata.npy', pad_to_360=False)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "rows=[]\n",
    "for X, y in data_loader:\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    row = model.encoder(X.float())\n",
    "    row = torch.cat([row.reshape(1,-1),y.reshape(1,-1).float()], dim=1)\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c0d3508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4085"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cecabf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = torch.cat(rows, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9006666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_labeled_data = encoded_data.detach().to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "454833a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/np_autoencoded_labeled_data.npy', np_labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "effe0220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 65]),\n",
       " tensor([[ 0.4013, -0.6855, -0.7156,  0.9339, -0.9558,  0.5300, -0.0857,  0.7046,\n",
       "           0.2912,  0.7087, -0.8098, -0.8930, -0.5535,  0.5503, -0.9506,  0.4161,\n",
       "           0.0843, -0.4683,  0.4343, -0.5010, -0.4567, -0.0906,  0.5301,  0.7316,\n",
       "           0.9533, -0.2443,  0.7769,  0.0584, -0.7406, -0.7253, -0.7416, -0.0751,\n",
       "          -0.3182, -0.3416,  0.7200, -0.5329, -0.6897, -0.0160,  0.1136, -0.4463,\n",
       "           0.3447, -0.5107, -0.6689,  0.3179, -0.1100, -0.1150,  0.0790,  0.7705,\n",
       "          -0.3329,  0.6714, -0.7256,  0.4391,  0.1403,  0.4815, -0.6231, -0.5074,\n",
       "           0.0524,  0.6013, -0.5924,  0.4243,  0.1845, -0.0379,  0.0665, -0.2875,\n",
       "           0.0000,  0.0000]], device='cuda:0', grad_fn=<CatBackward>))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.reshape(1,-1).shape, torch.cat([row.reshape(1,-1),y.reshape(1,-1).float()], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41131c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f1e045e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012076033279299736"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "487850cc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# persist the encoder\n",
    "\n",
    "\n",
    "with open('data/autoencoder.pic', 'bw') as f:\n",
    "    torch.save(model, f, pickle_protocol=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f0aeaf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/autoencoder.pic', 'rb') as f:\n",
    "    autoencoder = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2362dd75",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
