{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77083ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q PyAthena[SQLAlchemy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca30bd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9e93c115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8270c6",
   "metadata": {},
   "source": [
    "## Prepare Datasets for Predictor Training, Validation and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80073145",
   "metadata": {},
   "source": [
    "#### TS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942884b6",
   "metadata": {},
   "source": [
    "Import modules that build patient cohort, extract demographics and lab events data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d488990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a5a3103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import missingno as msno\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85ca4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataproc.cohort import query_esbl_pts, remove_dups, observation_window\n",
    "from dataproc import cohort\n",
    "from dataproc import create_dataset\n",
    "from dataproc.sampling import generate_samples\n",
    "\n",
    "from hyper_params import HyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5757fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hyperparams instance\n",
    "params = HyperParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ae28ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR='data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a46dd3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframe(df, filename, data_dir = DATA_DIR):\n",
    "    destination = f\"{DATA_DIR}/{filename}.parquet\"\n",
    "    df.to_parquet(destination)\n",
    "    \n",
    "    \n",
    "def load_dataframe(filename, data_dir = DATA_DIR):\n",
    "    destination = f\"{DATA_DIR}/{filename}.parquet\"\n",
    "    df = pd.read_parquet(destination)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b81c6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_sparse_columns(df, columns:list, max_sparsity_to_keep=0.9):\n",
    "    # count the missing values in each column\n",
    "    missing_values_counts = df[columns].isna().sum()\n",
    "    # percent of columns with rare values\n",
    "    max_missing_vals = max_sparsity_to_keep * df.shape[0]\n",
    "    sparse_columns = missing_values_counts[missing_values_counts > max_missing_vals].index.tolist()\n",
    "    # drop the rare labtests from the dataset\n",
    "    df = df.drop(columns=sparse_columns)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c375b",
   "metadata": {},
   "source": [
    "## create list of patients, max_observation_window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ecce4a",
   "metadata": {},
   "source": [
    "- create list of elibible patients\n",
    "\t- did not die during observation_window\n",
    "\t- were not discharbed during observation window\n",
    "- calculate index_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b812c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_pts_within_observation_window, view_name_all_pts_within_observation_window = cohort.query_all_pts_within_observation_window(params.observation_window_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4b55859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('default.all_pts_6_hours', (58397, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_name_all_pts_within_observation_window, df_all_pts_within_observation_window.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60e64d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>index_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50488</td>\n",
       "      <td>142899</td>\n",
       "      <td>2183-01-07 00:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19548</td>\n",
       "      <td>193954</td>\n",
       "      <td>2170-05-10 13:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84461</td>\n",
       "      <td>146684</td>\n",
       "      <td>2177-02-20 03:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1750</td>\n",
       "      <td>131278</td>\n",
       "      <td>2167-09-24 17:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30582</td>\n",
       "      <td>187871</td>\n",
       "      <td>2129-04-07 18:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  hadm_id          index_date\n",
       "0       50488   142899 2183-01-07 00:49:00\n",
       "1       19548   193954 2170-05-10 13:15:00\n",
       "2       84461   146684 2177-02-20 03:03:00\n",
       "3        1750   131278 2167-09-24 17:04:00\n",
       "4       30582   187871 2129-04-07 18:00:00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_pts_within_observation_window.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16315205",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_all_pts_within_observation_window, 'df_all_pts_within_observation_window')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7b1e42",
   "metadata": {},
   "source": [
    "## @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3012964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prev results\n",
    "view_name_all_pts_within_observation_window = 'default.all_pts_6_hours' \n",
    "df_all_pts_within_observation_window = load_dataframe('df_all_pts_within_observation_window')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b665d9a3",
   "metadata": {},
   "source": [
    "## generate features for all patients (under observation window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfd6c84",
   "metadata": {},
   "source": [
    "## Static features\n",
    "\t- save static feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1acb7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_static_data = create_dataset.static_data(hadm_ids_table = view_name_all_pts_within_observation_window)\n",
    "df_static_data = df_static_data.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65626b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_feature_names = df_static_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6340b4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hadm_id',\n",
       " 'admission_type',\n",
       " 'admission_location',\n",
       " 'insurance',\n",
       " 'language',\n",
       " 'religion',\n",
       " 'marital_status',\n",
       " 'ethnicity',\n",
       " 'gender',\n",
       " 'age']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da5956e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>language</th>\n",
       "      <th>religion</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165315</td>\n",
       "      <td>2196-04-09 12:26:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNOBTAINABLE</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>F</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152223</td>\n",
       "      <td>2153-09-03 07:15:00</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>M</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124321</td>\n",
       "      <td>2157-10-18 19:34:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>M</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161859</td>\n",
       "      <td>2139-06-06 16:14:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROTESTANT QUAKER</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129635</td>\n",
       "      <td>2160-11-02 02:06:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNOBTAINABLE</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>M</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id           admittime admission_type         admission_location  \\\n",
       "0   165315 2196-04-09 12:26:00      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "1   152223 2153-09-03 07:15:00       ELECTIVE  PHYS REFERRAL/NORMAL DELI   \n",
       "2   124321 2157-10-18 19:34:00      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "3   161859 2139-06-06 16:14:00      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "4   129635 2160-11-02 02:06:00      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "\n",
       "  insurance language           religion marital_status ethnicity gender  age  \n",
       "0   Private      NaN       UNOBTAINABLE        MARRIED     WHITE      F   64  \n",
       "1  Medicare      NaN           CATHOLIC        MARRIED     WHITE      M   71  \n",
       "2  Medicare     ENGL           CATHOLIC        MARRIED     WHITE      M   75  \n",
       "3   Private      NaN  PROTESTANT QUAKER         SINGLE     WHITE      M   39  \n",
       "4   Private      NaN       UNOBTAINABLE        MARRIED     WHITE      M   58  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_static_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7a641eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58397, 11)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_static_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f0ed9149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_static_data(dataset):\n",
    "    dataset['admission_location'] = \\\n",
    "    np.where(dataset['admission_location'].isin(['** INFO NOT AVAILABLE **']), 'EMERGENCY ROOM ADMIT',\n",
    "    np.where(dataset['admission_location'].isin(['TRANSFER FROM SKILLED NUR','TRANSFER FROM OTHER HEALT',\n",
    "                            'TRANSFER FROM HOSP/EXTRAM']), 'TRANSFER FROM MED FACILITY',dataset['admission_location']))\n",
    "    dataset['language'] = \\\n",
    "    np.where(~dataset['language'].isin(['ENGL','SPAN']),'OTHER',dataset['language'])\n",
    "\n",
    "    dataset['religion'] = \\\n",
    "    np.where(~dataset['religion'].isin(['CATHOLIC','NOT SPECIFIED','UNOBTAINABLE','PROTESTANT QUAKER','JEWISH']),'OTHER',\n",
    "    np.where(dataset['religion'].isin(['UNOBTAINABLE']),'NOT SPECIFIED', dataset['religion'] ))\n",
    "\n",
    "    dataset['ethnicity'] = \\\n",
    "    np.where(dataset['ethnicity'].isin(['ASIAN - CHINESE',\n",
    "                                        'ASIAN - ASIAN INDIAN',\n",
    "                                        'ASIAN - VIETNAMESE',\n",
    "                                        'ASIAN - OTHER',\n",
    "                                        'ASIAN - FILIPINO',\n",
    "                                        'ASIAN - CAMBODIAN']), 'ASIAN',\n",
    "    np.where(dataset['ethnicity'].isin(['WHITE - RUSSIAN',\n",
    "                                        'WHITE - BRAZILIAN',\n",
    "                                        'WHITE - OTHER EUROPEAN']),'WHITE',\n",
    "    np.where(dataset['ethnicity'].isin(['BLACK/CAPE VERDEAN',\n",
    "                                        'BLACK/HAITIAN',\n",
    "                                        'BLACK/AFRICAN']), 'BLACK/AFRICAN AMERICAN',\n",
    "    np.where(dataset['ethnicity'].isin(['HISPANIC/LATINO - PUERTO RICAN',\n",
    "                                       'HISPANIC/LATINO - DOMINICAN',\n",
    "                                       'HISPANIC/LATINO - SALVADORAN',\n",
    "                                       'HISPANIC/LATINO - CUBAN',\n",
    "                                       'HISPANIC/LATINO - MEXICAN']), 'HISPANIC OR LATINO',   \n",
    "    np.where(dataset['ethnicity'].isin(['MULTI RACE ETHNICITY',\n",
    "                                        'MIDDLE EASTERN',\n",
    "                                        'PORTUGUESE',\n",
    "                                        'AMERICAN INDIAN/ALASKA NATIVE',\n",
    "                                        'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER',\n",
    "                                        'AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE']), 'OTHER',\n",
    "    np.where(dataset['ethnicity'].isin(['UNABLE TO OBTAIN',\n",
    "                                        'PATIENT DECLINED TO ANSWER']), 'UNKNOWN/NOT SPECIFIED',\n",
    "    dataset['ethnicity']))))))\n",
    "    dataset['marital_status'] = dataset['marital_status'].fillna(value='UNKNOWN')\n",
    "    # clean the age column\n",
    "    threshold = 105\n",
    "    df_static_data['age'] = df_static_data['age'].apply(lambda x: x if x < threshold else np.nan)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4d07bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_static_data(df_static_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21fee4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_static_data, 'df_static_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c82a2",
   "metadata": {},
   "source": [
    "## @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bbfb0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prev results\n",
    "df_static_data = load_dataframe('df_static_data')\n",
    "static_feature_names = df_static_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f789ab",
   "metadata": {},
   "source": [
    "### Examine missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a29b58",
   "metadata": {},
   "source": [
    "### lab results\n",
    "- no cleaning now!\n",
    "- save lab features names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99195307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab_events = create_dataset.lab_events(view_name_all_pts_within_observation_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ad56013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab_events = df_lab_events.dropna(subset=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "927e468b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>value</th>\n",
       "      <th>flag</th>\n",
       "      <th>charttime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193313</td>\n",
       "      <td>50912</td>\n",
       "      <td>2.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>2153-12-10 22:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>193313</td>\n",
       "      <td>50960</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2153-12-10 22:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>193313</td>\n",
       "      <td>51146</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2153-12-10 22:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193313</td>\n",
       "      <td>51237</td>\n",
       "      <td>1.2</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>2153-12-10 22:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>193313</td>\n",
       "      <td>51250</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2153-12-10 22:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id  itemid value      flag           charttime\n",
       "0   193313   50912   2.0  abnormal 2153-12-10 22:40:00\n",
       "1   193313   50960   1.8       NaN 2153-12-10 22:40:00\n",
       "2   193313   51146   0.1       NaN 2153-12-10 22:40:00\n",
       "3   193313   51237   1.2  abnormal 2153-12-10 22:40:00\n",
       "4   193313   51250  89.0       NaN 2153-12-10 22:40:00"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lab_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0aa514c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abnormal    998353\n",
       "delta         7472\n",
       "Name: flag, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lab_events.flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "749cbecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2220908\n",
       "True     1005825\n",
       "Name: flag, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lab_events['flag'].fillna('False').map({'abnormal':True, 'delta':True, 'False': False}).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3e5d772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3226733, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lab_events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec484787",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_lab_events, 'df_lab_events')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67caa652",
   "metadata": {},
   "source": [
    "## @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d8ac1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prev results\n",
    "df_lab_events = load_dataframe('df_lab_events')\n",
    "# static_feature_names = df_static_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dc20184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_last_labtest_instance(df):\n",
    "    \"\"\"\n",
    "    select last instance of every type of test for a patient\n",
    "    \"\"\"\n",
    "    df = df.sort_values('charttime', axis=0)\n",
    "    df = df.drop_duplicates(subset=['hadm_id','itemid'], keep='last', ignore_index=True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def pivot_labtests_to_columns(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.pivot(index=['hadm_id'],columns=['itemid'],values=['value'])\n",
    "    df.columns = df.columns.to_flat_index()\n",
    "    df.columns = [str(colname[1]) for colname in df.columns]\n",
    "    df = df.reset_index(['hadm_id'])\n",
    "\n",
    "    return df\n",
    "\n",
    "        \n",
    "\n",
    "def pivot_flags_to_columns(df):\n",
    "    df = df.copy()\n",
    "    df['flag'] = df['flag'].fillna('False').map({'abnormal':1, 'delta':1, 'False': -1})\n",
    "    df['flag_name'] = df['itemid'].astype(str) + pd.Series([\"_flag\"] * df.shape[0]).astype(str)\n",
    "    df = df.pivot(index=['hadm_id'],columns=['flag_name'],values=['flag'])\n",
    "    df.columns = df.columns.to_flat_index()\n",
    "    df.columns = [str(colname[1]) for colname in df.columns]\n",
    "    df = df.fillna(0)\n",
    "    df = df.astype('int8')\n",
    "    df = df.reset_index(['hadm_id'])\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90522c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_labs = keep_last_labtest_instance(df_lab_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84197865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2403143, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected_labs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e80b48d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab_results = pivot_labtests_to_columns(df_selected_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d99cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_results_feature_names = df_lab_results.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8210b2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53874, 410)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lab_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7576f998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>50800</th>\n",
       "      <th>50801</th>\n",
       "      <th>50802</th>\n",
       "      <th>50803</th>\n",
       "      <th>50804</th>\n",
       "      <th>50805</th>\n",
       "      <th>50806</th>\n",
       "      <th>50808</th>\n",
       "      <th>50809</th>\n",
       "      <th>...</th>\n",
       "      <th>51513</th>\n",
       "      <th>51514</th>\n",
       "      <th>51515</th>\n",
       "      <th>51516</th>\n",
       "      <th>51517</th>\n",
       "      <th>51518</th>\n",
       "      <th>51519</th>\n",
       "      <th>51520</th>\n",
       "      <th>51523</th>\n",
       "      <th>51529</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>ART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100006</td>\n",
       "      <td>ART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOLD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id 50800 50801 50802 50803 50804 50805 50806 50808 50809  ... 51513  \\\n",
       "0   100001   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "1   100003   ART   NaN  -6.0   NaN  17.0   NaN   NaN  1.06   NaN  ...   NaN   \n",
       "2   100006   ART   NaN   0.0   NaN  27.0   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "3   100007   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "4   100009   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "\n",
       "  51514 51515 51516 51517 51518 51519 51520 51523 51529  \n",
       "0   NaN   NaN   2.0   NaN   NaN  NONE   NaN   NaN   NaN  \n",
       "1   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3   NEG   NaN   NaN   NaN   NaN   NaN   NaN  HOLD   NaN  \n",
       "4   NaN   NaN   1.0   NaN   NaN  NONE   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lab_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac515b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f829650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean categorical values\n",
    "df_lab_results['51501'] = np.where(df_lab_results['51501'].isin(['<1','1','2']), '0-2',\n",
    "                     np.where(df_lab_results['51501'].isin(['3','4']),'3-5', df_lab_results['51501']))\n",
    "\n",
    "df_lab_results['51506'] = np.where(df_lab_results['51506'].isin(['CLEAR']), 'Clear',\n",
    "                    np.where(df_lab_results['51506'].isin(['SLHAZY']), 'SlHazy',\n",
    "                    np.where(df_lab_results['51506'].isin(['HAZY']), 'Hazy',\n",
    "                    np.where(df_lab_results['51506'].isin(['SlCloudy']),'SlCldy',\n",
    "                    np.where(df_lab_results['51506'].isin(['CLOUDY']),'Cloudy',df_lab_results['51506'])))))\n",
    "\n",
    "df_lab_results['51463'] = np.where(df_lab_results['51463'].isin(['0']), 'NEG',\n",
    "                    np.where(df_lab_results['51463'].isin(['NOTDONE']), 'NONE',\n",
    "                    np.where(df_lab_results['51463'].isin(['LRG']), 'MANY', df_lab_results['51463'])))\n",
    "\n",
    "df_lab_results['51508'] = np.where(df_lab_results['51508'].isin(['YELLOW','YEL']), 'Yellow',\n",
    "                    np.where(df_lab_results['51508'].isin(['STRAW']), 'Straw',\n",
    "                    np.where(df_lab_results['51508'].isin(['AMBER','AMB']), 'Amber',\n",
    "                    np.where(df_lab_results['51508'].isin(['RED']), 'Red',\n",
    "                    np.where(df_lab_results['51508'].isin(['ORANGE']), 'Orange',\n",
    "                    np.where(df_lab_results['51508'].isin(['DKAMB','DKAMBER']), 'DkAmb',\n",
    "                    np.where(df_lab_results['51508'].isin([' ']), np.nan, df_lab_results['51508'])))))))\n",
    "\n",
    "# >80 is a category by iteslef, so keeping it. \n",
    "# df_lab_results['51484'] = np.where(df_lab_results['51484'].isin(['>80']), '80',df_lab_results['51484'])\n",
    "\n",
    "# >300 is a category by itself, so keeping it\n",
    "# df_lab_results['51492'] = np.where(df_lab_results['51492'].isin(['>300']), '300',\n",
    "#                     np.where(df_lab_results['51492'].isin([' ']), np.nan, df_lab_results['51492']))\n",
    "df_lab_results['51492'] = np.where(df_lab_results['51492'].isin([' ']), np.nan, df_lab_results['51492'])\n",
    "\n",
    "df_lab_results['51514'] = np.where(df_lab_results['51514'].isin(['.2']), '0.2',\n",
    "                    np.where(df_lab_results['51514'].isin(['>8']), '>8.0',\n",
    "                    np.where(df_lab_results['51514'].isin(['>12']), '>12.0',\n",
    "                    np.where(df_lab_results['51514'].isin(['NotDone',' ']), np.nan, df_lab_results['51514']))))\n",
    "\n",
    "df_lab_results['51003'] = np.where(df_lab_results['51003'].isin({'<0.01','LESS THAN 0.01', '<0.010', 'LESS THAN 0.010','<0.10', '<0.02', 'LESS THAN 0.1' }), '0.001',\n",
    "                    np.where(df_lab_results['51003'].isin({ 'GREATER THAN 25.0', '>25.0', '>25', 'GREATER THAN 25', '>25.00' }), '30.0',\n",
    "                    df_lab_results['51003']))\n",
    "\n",
    "\n",
    "df_lab_results['51519'] = np.where(df_lab_results['51519'].isin(['0', 'N']), 'NONE',\n",
    "                    np.where(df_lab_results['51519'].isin(['NOTDONE']), np.nan, df_lab_results['51519']))\n",
    "\n",
    "df_lab_results['51266'] = np.where(df_lab_results['51266'].isin(['UNABLE TO ESTIMATE DUE TO PLATELET CLUMPS']), 'NOTDETECTED', df_lab_results['51266'])\n",
    "\n",
    "df_lab_results['51478'] = df_lab_results['51478'].map(\n",
    "    {\n",
    "        'Neg': 'NEG',\n",
    "        'N': 'NEG',\n",
    "    }\n",
    ")\n",
    "\n",
    "df_lab_results['51484'] = df_lab_results['51484'].map(\n",
    "    {\n",
    "        'T': 'TR',\n",
    "        'Tr': 'TR',\n",
    "        'Neg': 'NEG',\n",
    "        '>80': '150.0'\n",
    "    }\n",
    ")\n",
    "df_lab_results['51492'] = df_lab_results['51492'].map(\n",
    "    {\n",
    "        'Neg': 'NEG',\n",
    "        '>600': '600.0',\n",
    "        '>300': '500.0',\n",
    "    }\n",
    ")\n",
    "df_lab_results['51463'] = df_lab_results['51463'].map(\n",
    "    {\n",
    "        ' ': 'NONE',\n",
    "        'F': 'FEW',\n",
    "        'MOD-': 'MOD',\n",
    "        '1.0': 'RARE',\n",
    "        '7I': 'NONE',\n",
    "        '2.0': 'FEW'\n",
    "    }\n",
    ")\n",
    "df_lab_results['51003'] = np.where(df_lab_results['51003'].isin({'NotDone', 'NOT DONE', 'ERROR', 'NOT DONE , TOTAL CK LESS THAN 100'}), np.nan,\n",
    "                    np.where(df_lab_results['51003'].isin({ '>500', 'GREATER THAN 500' }), '600.0',\n",
    "                             np.where(df_lab_results['51003'].isin({ '<1' }), '0.0', df_lab_results['51003'])))\n",
    "df_lab_results['50922'] = np.where(df_lab_results['50922'].isin({'NEG', 'NEGATIVE', 'ERROR'}), -1.0, df_lab_results['50922'])\n",
    "\n",
    "df_lab_results['51493'] = df_lab_results['51493'].map(\n",
    "    {'0-2': '1.0',\n",
    "     '3-5': '4.0',\n",
    "     '11-20': '15.0',\n",
    "     '>50': '80.0',\n",
    "     '6-10': '8.0',\n",
    "     '21-50': '35.0',\n",
    "     '<1': '0.01',\n",
    "     '>1000': '1100.0',\n",
    "     'O-2': '1.0',\n",
    "     ' 3-5': '4.0',\n",
    "     ' ': np.nan,\n",
    "     'LOADED': np.nan,\n",
    "     ' 0-2': '1.0',\n",
    "     'NOTDONE': np.nan,\n",
    "     '0-20-2': np.nan,\n",
    "     '0-2+' : np.nan,\n",
    "     'TNTC' : np.nan,\n",
    "     '3/5'  : np.nan,\n",
    "     '21-200-2':  np.nan})\n",
    "\n",
    "df_lab_results['51516'] = df_lab_results['51516'].map(\n",
    "    {'0-2': '1.0',\n",
    "     '3-5': '4.0',\n",
    "     '11-20': '15.0',\n",
    "     '>50': '80.0',\n",
    "     '6-10': '8.0',\n",
    "     '21-50': '35.0',\n",
    "     '<1': '0.01',\n",
    "     '>1000': '1100.0',\n",
    "     'O-2': '1.0',\n",
    "     ' 3-5': '4.0',\n",
    "     ' ': np.nan,\n",
    "     'LOADED': np.nan,\n",
    "     ' 0-2': '1.0',\n",
    "     'NOTDONE': np.nan,\n",
    "     '0-20-2': np.nan,\n",
    "     '0-2+' : np.nan,\n",
    "     'TNTC' : np.nan,\n",
    "     '3/5'  : np.nan,\n",
    "     '21-200-2':  np.nan})\n",
    "\n",
    "\n",
    "df_lab_results['51476'] = df_lab_results['51476'].map(\n",
    "    {'0-2': '1.0',\n",
    "     '3-5': '4.0',\n",
    "     '11-20': '15.0',\n",
    "     '>50': '80.0',\n",
    "     '6-10': '8.0',\n",
    "     '21-50': '35.0',\n",
    "     '<1': '0.01',\n",
    "     '>1000': '1100.0',\n",
    "     'O-2': '1.0',\n",
    "     ' 3-5': '4.0',\n",
    "     ' ': np.nan,\n",
    "     'LOADED': np.nan,\n",
    "     ' 0-2': '1.0',\n",
    "     'NOTDONE': np.nan,\n",
    "     '0-20-2': np.nan,\n",
    "     '0-2+' : np.nan,\n",
    "     'TNTC' : np.nan,\n",
    "     '3/5'  : np.nan,\n",
    "     '21-200-2':  np.nan,\n",
    "    '0-2,TRANS': '1.0',\n",
    "    '<1 /HPF': '0.5',\n",
    "     '11-20-': '15.0',\n",
    "     '0.-2': '1.0',\n",
    "     ' 0-2': '1.0',\n",
    "    })\n",
    "\n",
    "df_lab_results['50911'] = df_lab_results['50911'].map(\n",
    "    {\n",
    " 'NotDone': np.nan,\n",
    " '>500' : '600.0',\n",
    " 'GREATER THAN 500' : '550.0',\n",
    " 'NOT DONE' : np.nan,\n",
    " '<1' : '0.0',\n",
    " 'ERROR': np.nan,\n",
    " 'NOT DONE , TOTAL CK LESS THAN 100':  np.nan}\n",
    ")\n",
    "\n",
    "# dropping non interesting columns\n",
    "df_lab_results = df_lab_results.drop(columns=['50827', '50856', '51100','51482', '50981'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0001867d",
   "metadata": {},
   "source": [
    "#### Drop sparse columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae5784d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab_results = drop_sparse_columns(\n",
    "    df_lab_results, \n",
    "    columns=  df_lab_results.drop(columns=['hadm_id']).columns.tolist(), \n",
    "    max_sparsity_to_keep=0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96160872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_columns_types(df):\n",
    "    df = df.convert_dtypes(infer_objects=True)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9900597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_data_types(df, columns=None):\n",
    "    if columns is None:\n",
    "        columns = df.columns.tolist()\n",
    "    numeric = []\n",
    "    categorical = []\n",
    "    weird = []\n",
    "    N = df.shape[0]\n",
    "    for code in columns:\n",
    "        n_missing = df_lab_results[code].isna().sum()\n",
    "        size = N - n_missing\n",
    "        size_unique = df_lab_results[code].nunique()\n",
    "        sum_na = pd.to_numeric(df_lab_results[code][df_lab_results[code].notna()], errors='coerce').isna().sum()\n",
    "        if sum_na / size < 0.05:\n",
    "            numeric.append(code)\n",
    "        elif sum_na / size > 0.05 and size_unique < 100:\n",
    "            categorical.append(code)\n",
    "        else:\n",
    "            weird.append(code)\n",
    "    return numeric, categorical, weird\n",
    "\n",
    "def set_numeric_columns(df, numeric_columns: list):\n",
    "    df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b23d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric, categorical, weird = detect_data_types(df_lab_results.drop(columns=['hadm_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15b9ce37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>50800</th>\n",
       "      <th>50801</th>\n",
       "      <th>50802</th>\n",
       "      <th>50803</th>\n",
       "      <th>50804</th>\n",
       "      <th>50806</th>\n",
       "      <th>50808</th>\n",
       "      <th>50809</th>\n",
       "      <th>50810</th>\n",
       "      <th>...</th>\n",
       "      <th>51487</th>\n",
       "      <th>51491</th>\n",
       "      <th>51493</th>\n",
       "      <th>51498</th>\n",
       "      <th>51506</th>\n",
       "      <th>51508</th>\n",
       "      <th>51514</th>\n",
       "      <th>51516</th>\n",
       "      <th>51519</th>\n",
       "      <th>51523</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>ART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100006</td>\n",
       "      <td>ART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.013</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53869</th>\n",
       "      <td>199993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53870</th>\n",
       "      <td>199994</td>\n",
       "      <td>ART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53871</th>\n",
       "      <td>199995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53872</th>\n",
       "      <td>199998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.010</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53873</th>\n",
       "      <td>199999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53874 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hadm_id 50800  50801  50802  50803  50804  50806  50808  50809  50810  \\\n",
       "0       100001   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1       100003   ART    NaN   -6.0    NaN   17.0    NaN   1.06    NaN   23.0   \n",
       "2       100006   ART    NaN    0.0    NaN   27.0    NaN    NaN    NaN    NaN   \n",
       "3       100007   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4       100009   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "...        ...   ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "53869   199993   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "53870   199994   ART    NaN   -3.0    NaN   27.0    NaN   1.32    NaN    NaN   \n",
       "53871   199995   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "53872   199998   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "53873   199999   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "       ...  51487 51491  51493  51498  51506   51508  51514  51516  51519  \\\n",
       "0      ...    NaN   7.5    NaN  1.008    NaN     NaN    NaN    NaN   NONE   \n",
       "1      ...    NaN   NaN    NaN    NaN    NaN     NaN    NaN    NaN    NaN   \n",
       "2      ...    NaN   NaN    NaN    NaN    NaN     NaN    NaN    NaN    NaN   \n",
       "3      ...    NEG   8.0    NaN  1.013  Clear  Yellow    NEG    NaN    NaN   \n",
       "4      ...    NaN   5.0    NaN  1.014    NaN     NaN    NaN    NaN   NONE   \n",
       "...    ...    ...   ...    ...    ...    ...     ...    ...    ...    ...   \n",
       "53869  ...    NaN   NaN    NaN    NaN    NaN     NaN    NaN    NaN    NaN   \n",
       "53870  ...    NaN   NaN    NaN    NaN    NaN     NaN    NaN    NaN    NaN   \n",
       "53871  ...    NaN   NaN    NaN    NaN    NaN     NaN    NaN    NaN    NaN   \n",
       "53872  ...    NEG   6.5    NaN  1.010  Clear  Yellow    4.0    NaN    NaN   \n",
       "53873  ...    NaN   5.0    NaN  1.009    NaN     NaN    NaN    NaN   NONE   \n",
       "\n",
       "       51523  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3       HOLD  \n",
       "4        NaN  \n",
       "...      ...  \n",
       "53869    NaN  \n",
       "53870    NaN  \n",
       "53871    NaN  \n",
       "53872    NaN  \n",
       "53873    NaN  \n",
       "\n",
       "[53874 rows x 112 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_numeric_columns(df_lab_results, numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e38cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_lab_results, 'df_lab_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e42def9",
   "metadata": {},
   "source": [
    "## @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d77efe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prev results\n",
    "df_lab_results = load_dataframe('df_lab_results')\n",
    "lab_results_feature_names = df_lab_results.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13658b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab_flags = pivot_flags_to_columns(df_selected_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "daf52c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_flags_feature_names = df_lab_flags.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b00fba33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53874, 410)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lab_flags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41c68d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>50800_flag</th>\n",
       "      <th>50801_flag</th>\n",
       "      <th>50802_flag</th>\n",
       "      <th>50803_flag</th>\n",
       "      <th>50804_flag</th>\n",
       "      <th>50805_flag</th>\n",
       "      <th>50806_flag</th>\n",
       "      <th>50808_flag</th>\n",
       "      <th>50809_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>51513_flag</th>\n",
       "      <th>51514_flag</th>\n",
       "      <th>51515_flag</th>\n",
       "      <th>51516_flag</th>\n",
       "      <th>51517_flag</th>\n",
       "      <th>51518_flag</th>\n",
       "      <th>51519_flag</th>\n",
       "      <th>51520_flag</th>\n",
       "      <th>51523_flag</th>\n",
       "      <th>51529_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100006</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id  50800_flag  50801_flag  50802_flag  50803_flag  50804_flag  \\\n",
       "0   100001           0           0           0           0           0   \n",
       "1   100003          -1           0          -1           0           1   \n",
       "2   100006          -1           0          -1           0          -1   \n",
       "3   100007           0           0           0           0           0   \n",
       "4   100009           0           0           0           0           0   \n",
       "\n",
       "   50805_flag  50806_flag  50808_flag  50809_flag  ...  51513_flag  \\\n",
       "0           0           0           0           0  ...           0   \n",
       "1           0           0           1           0  ...           0   \n",
       "2           0           0           0           0  ...           0   \n",
       "3           0           0           0           0  ...           0   \n",
       "4           0           0           0           0  ...           0   \n",
       "\n",
       "   51514_flag  51515_flag  51516_flag  51517_flag  51518_flag  51519_flag  \\\n",
       "0           0           0          -1           0           0          -1   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3          -1           0           0           0           0           0   \n",
       "4           0           0          -1           0           0          -1   \n",
       "\n",
       "   51520_flag  51523_flag  51529_flag  \n",
       "0           0           0           0  \n",
       "1           0           0           0  \n",
       "2           0           0           0  \n",
       "3           0          -1           0  \n",
       "4           0           0           0  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lab_flags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a659765",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_lab_flags, 'df_lab_flags')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460fc4f",
   "metadata": {},
   "source": [
    "## @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2b7dd3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prev results\n",
    "df_lab_flags = load_dataframe('df_lab_flags')\n",
    "lab_flags_feature_names = df_lab_flags.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13efb985",
   "metadata": {},
   "source": [
    "## join to a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc3b0088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab = df_lab_results.merge(df_lab_flags,how='left', on=['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c08254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab = df_lab.set_index('hadm_id').reindex(sorted(df_lab.columns), axis=1).drop(columns=['hadm_id']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5765c04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>50800</th>\n",
       "      <th>50800_flag</th>\n",
       "      <th>50801</th>\n",
       "      <th>50801_flag</th>\n",
       "      <th>50802</th>\n",
       "      <th>50802_flag</th>\n",
       "      <th>50803</th>\n",
       "      <th>50803_flag</th>\n",
       "      <th>50804</th>\n",
       "      <th>...</th>\n",
       "      <th>51516</th>\n",
       "      <th>51516_flag</th>\n",
       "      <th>51517_flag</th>\n",
       "      <th>51518_flag</th>\n",
       "      <th>51519</th>\n",
       "      <th>51519_flag</th>\n",
       "      <th>51520_flag</th>\n",
       "      <th>51523</th>\n",
       "      <th>51523_flag</th>\n",
       "      <th>51529_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>ART</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100006</td>\n",
       "      <td>ART</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100007</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HOLD</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100009</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id 50800  50800_flag  50801  50801_flag  50802  50802_flag  50803  \\\n",
       "0   100001  None           0    NaN           0    NaN           0    NaN   \n",
       "1   100003   ART          -1    NaN           0   -6.0          -1    NaN   \n",
       "2   100006   ART          -1    NaN           0    0.0          -1    NaN   \n",
       "3   100007  None           0    NaN           0    NaN           0    NaN   \n",
       "4   100009  None           0    NaN           0    NaN           0    NaN   \n",
       "\n",
       "   50803_flag  50804  ...  51516  51516_flag  51517_flag  51518_flag  51519  \\\n",
       "0           0    NaN  ...    NaN          -1           0           0   NONE   \n",
       "1           0   17.0  ...    NaN           0           0           0   None   \n",
       "2           0   27.0  ...    NaN           0           0           0   None   \n",
       "3           0    NaN  ...    NaN           0           0           0   None   \n",
       "4           0    NaN  ...    NaN          -1           0           0   NONE   \n",
       "\n",
       "   51519_flag  51520_flag  51523  51523_flag  51529_flag  \n",
       "0          -1           0   None           0           0  \n",
       "1           0           0   None           0           0  \n",
       "2           0           0   None           0           0  \n",
       "3           0           0   HOLD          -1           0  \n",
       "4          -1           0   None           0           0  \n",
       "\n",
       "[5 rows x 521 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "621d05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab = df_lab.set_index(['hadm_id'])\n",
    "df_static_data = df_static_data.set_index(['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c18bc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab = df_lab.sort_values('hadm_id', axis=0)\n",
    "df_static_data = df_static_data.sort_values('hadm_id', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aa332df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_unprocessed = df_lab.join(df_static_data,how='inner') # join on index hadm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "15c6316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_unprocessed_feature_names = df_dataset_unprocessed.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6bcc680b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50800_flag</th>\n",
       "      <th>50801_flag</th>\n",
       "      <th>50802_flag</th>\n",
       "      <th>50803_flag</th>\n",
       "      <th>50804_flag</th>\n",
       "      <th>50805_flag</th>\n",
       "      <th>50806_flag</th>\n",
       "      <th>50808_flag</th>\n",
       "      <th>50809_flag</th>\n",
       "      <th>50810_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>51529_flag</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>language</th>\n",
       "      <th>religion</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hadm_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>CLINIC REFERRAL/PREMATURE</td>\n",
       "      <td>Private</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>PROTESTANT QUAKER</td>\n",
       "      <td>DIVORCED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>F</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>Private</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>NOT SPECIFIED</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>M</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100006</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>Private</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NOT SPECIFIED</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>F</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>Private</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>JEWISH</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>F</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100009</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM MED FACILITY</td>\n",
       "      <td>Private</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>M</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         50800_flag  50801_flag  50802_flag  50803_flag  50804_flag  \\\n",
       "hadm_id                                                               \n",
       "100001            0           0           0           0           0   \n",
       "100003           -1           0          -1           0           1   \n",
       "100006           -1           0          -1           0          -1   \n",
       "100007            0           0           0           0           0   \n",
       "100009            0           0           0           0           0   \n",
       "\n",
       "         50805_flag  50806_flag  50808_flag  50809_flag  50810_flag  ...  \\\n",
       "hadm_id                                                              ...   \n",
       "100001            0           0           0           0           0  ...   \n",
       "100003            0           0           1           0          -1  ...   \n",
       "100006            0           0           0           0           0  ...   \n",
       "100007            0           0           0           0           0  ...   \n",
       "100009            0           0           0           0           0  ...   \n",
       "\n",
       "         51529_flag  admission_type          admission_location  insurance  \\\n",
       "hadm_id                                                                      \n",
       "100001            0       EMERGENCY   CLINIC REFERRAL/PREMATURE    Private   \n",
       "100003            0       EMERGENCY        EMERGENCY ROOM ADMIT    Private   \n",
       "100006            0       EMERGENCY        EMERGENCY ROOM ADMIT    Private   \n",
       "100007            0       EMERGENCY        EMERGENCY ROOM ADMIT    Private   \n",
       "100009            0       EMERGENCY  TRANSFER FROM MED FACILITY    Private   \n",
       "\n",
       "         language           religion  marital_status               ethnicity  \\\n",
       "hadm_id                                                                        \n",
       "100001       ENGL  PROTESTANT QUAKER        DIVORCED                   WHITE   \n",
       "100003       ENGL      NOT SPECIFIED          SINGLE                   WHITE   \n",
       "100006      OTHER      NOT SPECIFIED          SINGLE  BLACK/AFRICAN AMERICAN   \n",
       "100007      OTHER             JEWISH         MARRIED                   WHITE   \n",
       "100009      OTHER           CATHOLIC         MARRIED                   WHITE   \n",
       "\n",
       "         gender   age  \n",
       "hadm_id                \n",
       "100001        F  35.0  \n",
       "100003        M  59.0  \n",
       "100006        F  48.0  \n",
       "100007        F  73.0  \n",
       "100009        M  60.0  \n",
       "\n",
       "[5 rows x 418 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_unprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "71e49510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53874, 418)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_unprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f8219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "34887260",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_dataset_unprocessed, 'df_dataset_unprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2aeb8",
   "metadata": {},
   "source": [
    "### @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ce86a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prev results\n",
    "df_dataset_unprocessed = load_dataframe('df_dataset_unprocessed')\n",
    "df_dataset_unprocessed_feature_names = df_dataset_unprocessed.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f6067c",
   "metadata": {},
   "source": [
    "### numeric values: clean and standardize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "caf60615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanardize_numeric_values(df, list_of_clms=None, replace_missing=False, ):\n",
    "    \"\"\"\n",
    "    Use the median and interquartile range to \n",
    "    standardize the numeric variables\n",
    "    value = (value – median) / (p75 – p25)\n",
    "    \"\"\"\n",
    "    if list_of_clms is None:\n",
    "        list_of_clms = df_stats.columns.tolist()\n",
    "    df_stats = df[list_of_clms].describe(percentiles=[.01,.25, .5, .75, .95, .99])\n",
    "    list_of_clms = df_stats.columns.tolist()\n",
    "    \n",
    "    for code in list_of_clms:\n",
    "        median = df_stats[code]['50%']\n",
    "        p25 = df_stats[code]['1%']\n",
    "        p75 = df_stats[code]['99%']\n",
    "        df[code] = (df[code] - median) / (p75 - p25)\n",
    "    return df\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def replace_missing_val(df, list_of_clms, how='median'):\n",
    "    \"\"\"\n",
    "    Imputation of missing values using median\n",
    "    \"\"\"\n",
    "    temp_df = df[list_of_clms]\n",
    "    imp = SimpleImputer(strategy=how)\n",
    "    df_prc = imp.fit_transform(temp_df)\n",
    "    temp_df = pd.DataFrame(df_prc, columns=list_of_clms, index=df.index)\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ea10dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_standardize = [col for col in df_dataset_unprocessed.columns.tolist() if not col.endswith('_flag')]\n",
    "df_dataset_unprocessed = stanardize_numeric_values(df_dataset_unprocessed, columns_to_standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1dd822ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df_dataset_unprocessed.select_dtypes('number')\n",
    "numeric_cols = [col for col in numeric_cols if not col.endswith('_flag')]\n",
    "# df_dataset_unprocessed = replace_missing_val(df_dataset_unprocessed, numeric_cols, how='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "732e2547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dataset_unprocessed = \n",
    "\n",
    "df_new_numeric = replace_missing_val(df_dataset_unprocessed, numeric_cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fd9c87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_unprocessed = df_dataset_unprocessed.drop(columns=numeric_cols).join(df_new_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbab3a5",
   "metadata": {},
   "source": [
    "### categorical values: One Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1d19e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df_dataset_unprocessed.select_dtypes('object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d2d3d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_processed = pd.get_dummies(df_dataset_unprocessed, columns=categorical_cols, dummy_na=True, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8df8c0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50800_flag</th>\n",
       "      <th>50801_flag</th>\n",
       "      <th>50802_flag</th>\n",
       "      <th>50803_flag</th>\n",
       "      <th>50804_flag</th>\n",
       "      <th>50805_flag</th>\n",
       "      <th>50806_flag</th>\n",
       "      <th>50808_flag</th>\n",
       "      <th>50809_flag</th>\n",
       "      <th>50810_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnicity_HISPANIC/LATINO - GUATEMALAN</th>\n",
       "      <th>ethnicity_HISPANIC/LATINO - HONDURAN</th>\n",
       "      <th>ethnicity_OTHER</th>\n",
       "      <th>ethnicity_SOUTH AMERICAN</th>\n",
       "      <th>ethnicity_UNKNOWN/NOT SPECIFIED</th>\n",
       "      <th>ethnicity_WHITE</th>\n",
       "      <th>ethnicity_WHITE - EASTERN EUROPEAN</th>\n",
       "      <th>ethnicity_nan</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_nan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hadm_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100006</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100009</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199994</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53874 rows × 459 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         50800_flag  50801_flag  50802_flag  50803_flag  50804_flag  \\\n",
       "hadm_id                                                               \n",
       "100001            0           0           0           0           0   \n",
       "100003           -1           0          -1           0           1   \n",
       "100006           -1           0          -1           0          -1   \n",
       "100007            0           0           0           0           0   \n",
       "100009            0           0           0           0           0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "199993            0           0           0           0           0   \n",
       "199994           -1           0          -1           0          -1   \n",
       "199995            0           0           0           0           0   \n",
       "199998            0           0           0           0           0   \n",
       "199999            0           0           0           0           0   \n",
       "\n",
       "         50805_flag  50806_flag  50808_flag  50809_flag  50810_flag  ...  \\\n",
       "hadm_id                                                              ...   \n",
       "100001            0           0           0           0           0  ...   \n",
       "100003            0           0           1           0          -1  ...   \n",
       "100006            0           0           0           0           0  ...   \n",
       "100007            0           0           0           0           0  ...   \n",
       "100009            0           0           0           0           0  ...   \n",
       "...             ...         ...         ...         ...         ...  ...   \n",
       "199993            0           0           0           0           0  ...   \n",
       "199994            0           0          -1           0           0  ...   \n",
       "199995            0           0           0           0           0  ...   \n",
       "199998            0           0           0           0           0  ...   \n",
       "199999            0           0           0           0           0  ...   \n",
       "\n",
       "         ethnicity_HISPANIC/LATINO - GUATEMALAN  \\\n",
       "hadm_id                                           \n",
       "100001                                        0   \n",
       "100003                                        0   \n",
       "100006                                        0   \n",
       "100007                                        0   \n",
       "100009                                        0   \n",
       "...                                         ...   \n",
       "199993                                        0   \n",
       "199994                                        0   \n",
       "199995                                        0   \n",
       "199998                                        0   \n",
       "199999                                        0   \n",
       "\n",
       "         ethnicity_HISPANIC/LATINO - HONDURAN  ethnicity_OTHER  \\\n",
       "hadm_id                                                          \n",
       "100001                                      0                0   \n",
       "100003                                      0                0   \n",
       "100006                                      0                0   \n",
       "100007                                      0                0   \n",
       "100009                                      0                0   \n",
       "...                                       ...              ...   \n",
       "199993                                      0                0   \n",
       "199994                                      0                0   \n",
       "199995                                      0                0   \n",
       "199998                                      0                0   \n",
       "199999                                      0                0   \n",
       "\n",
       "         ethnicity_SOUTH AMERICAN  ethnicity_UNKNOWN/NOT SPECIFIED  \\\n",
       "hadm_id                                                              \n",
       "100001                          0                                0   \n",
       "100003                          0                                0   \n",
       "100006                          0                                0   \n",
       "100007                          0                                0   \n",
       "100009                          0                                0   \n",
       "...                           ...                              ...   \n",
       "199993                          0                                1   \n",
       "199994                          0                                0   \n",
       "199995                          0                                0   \n",
       "199998                          0                                0   \n",
       "199999                          0                                0   \n",
       "\n",
       "         ethnicity_WHITE  ethnicity_WHITE - EASTERN EUROPEAN  ethnicity_nan  \\\n",
       "hadm_id                                                                       \n",
       "100001                 1                                   0              0   \n",
       "100003                 1                                   0              0   \n",
       "100006                 0                                   0              0   \n",
       "100007                 1                                   0              0   \n",
       "100009                 1                                   0              0   \n",
       "...                  ...                                 ...            ...   \n",
       "199993                 0                                   0              0   \n",
       "199994                 1                                   0              0   \n",
       "199995                 1                                   0              0   \n",
       "199998                 1                                   0              0   \n",
       "199999                 1                                   0              0   \n",
       "\n",
       "         gender_M  gender_nan  \n",
       "hadm_id                        \n",
       "100001          0           0  \n",
       "100003          1           0  \n",
       "100006          0           0  \n",
       "100007          0           0  \n",
       "100009          1           0  \n",
       "...           ...         ...  \n",
       "199993          1           0  \n",
       "199994          0           0  \n",
       "199995          1           0  \n",
       "199998          1           0  \n",
       "199999          1           0  \n",
       "\n",
       "[53874 rows x 459 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_processed.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "142583cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50800_flag</th>\n",
       "      <th>50801_flag</th>\n",
       "      <th>50802_flag</th>\n",
       "      <th>50803_flag</th>\n",
       "      <th>50804_flag</th>\n",
       "      <th>50805_flag</th>\n",
       "      <th>50806_flag</th>\n",
       "      <th>50808_flag</th>\n",
       "      <th>50809_flag</th>\n",
       "      <th>50810_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnicity_HISPANIC/LATINO - GUATEMALAN</th>\n",
       "      <th>ethnicity_HISPANIC/LATINO - HONDURAN</th>\n",
       "      <th>ethnicity_OTHER</th>\n",
       "      <th>ethnicity_SOUTH AMERICAN</th>\n",
       "      <th>ethnicity_UNKNOWN/NOT SPECIFIED</th>\n",
       "      <th>ethnicity_WHITE</th>\n",
       "      <th>ethnicity_WHITE - EASTERN EUROPEAN</th>\n",
       "      <th>ethnicity_nan</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_nan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hadm_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100006</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100009</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 459 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         50800_flag  50801_flag  50802_flag  50803_flag  50804_flag  \\\n",
       "hadm_id                                                               \n",
       "100001            0           0           0           0           0   \n",
       "100003           -1           0          -1           0           1   \n",
       "100006           -1           0          -1           0          -1   \n",
       "100007            0           0           0           0           0   \n",
       "100009            0           0           0           0           0   \n",
       "\n",
       "         50805_flag  50806_flag  50808_flag  50809_flag  50810_flag  ...  \\\n",
       "hadm_id                                                              ...   \n",
       "100001            0           0           0           0           0  ...   \n",
       "100003            0           0           1           0          -1  ...   \n",
       "100006            0           0           0           0           0  ...   \n",
       "100007            0           0           0           0           0  ...   \n",
       "100009            0           0           0           0           0  ...   \n",
       "\n",
       "         ethnicity_HISPANIC/LATINO - GUATEMALAN  \\\n",
       "hadm_id                                           \n",
       "100001                                        0   \n",
       "100003                                        0   \n",
       "100006                                        0   \n",
       "100007                                        0   \n",
       "100009                                        0   \n",
       "\n",
       "         ethnicity_HISPANIC/LATINO - HONDURAN  ethnicity_OTHER  \\\n",
       "hadm_id                                                          \n",
       "100001                                      0                0   \n",
       "100003                                      0                0   \n",
       "100006                                      0                0   \n",
       "100007                                      0                0   \n",
       "100009                                      0                0   \n",
       "\n",
       "         ethnicity_SOUTH AMERICAN  ethnicity_UNKNOWN/NOT SPECIFIED  \\\n",
       "hadm_id                                                              \n",
       "100001                          0                                0   \n",
       "100003                          0                                0   \n",
       "100006                          0                                0   \n",
       "100007                          0                                0   \n",
       "100009                          0                                0   \n",
       "\n",
       "         ethnicity_WHITE  ethnicity_WHITE - EASTERN EUROPEAN  ethnicity_nan  \\\n",
       "hadm_id                                                                       \n",
       "100001                 1                                   0              0   \n",
       "100003                 1                                   0              0   \n",
       "100006                 0                                   0              0   \n",
       "100007                 1                                   0              0   \n",
       "100009                 1                                   0              0   \n",
       "\n",
       "         gender_M  gender_nan  \n",
       "hadm_id                        \n",
       "100001          0           0  \n",
       "100003          1           0  \n",
       "100006          0           0  \n",
       "100007          0           0  \n",
       "100009          1           0  \n",
       "\n",
       "[5 rows x 459 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "11942094",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_dataset_processed, 'df_dataset_processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b8fab",
   "metadata": {},
   "source": [
    "## @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6d3f8ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_processed = load_dataframe('df_dataset_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "42c76e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_dataset_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b45f8d",
   "metadata": {},
   "source": [
    "## Build Dataset for training AutoEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c39440a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['y']=np.zeros((df_features.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "65b59f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata = df_features.to_numpy()\n",
    "# Save to a file\n",
    "np.save('data/fulldata.npy', fulldata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91143676",
   "metadata": {},
   "source": [
    "## Load Patients cohort\n",
    "hadm_id, \n",
    "class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "08141215",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = cohort.query_esbl_pts(params.observation_window_hours)\n",
    "df_cohort = cohort.remove_dups(df_cohort)\n",
    "df_cohort = df_cohort[['hadm_id', 'RESISTANT_YN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0c3e670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4719, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cohort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e96772e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_cohort, 'df_cohort')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682e2ea6",
   "metadata": {},
   "source": [
    "## @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a510094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = load_dataframe('df_cohort')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea7cdf4",
   "metadata": {},
   "source": [
    "Join the cohort on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "09b21573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_data = df_cohort.set_index(['hadm_id']).join(df_features.reset_index().set_index(['hadm_id']), how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "87454ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_data = df_full_data.rename(columns={'RESISTANT_YN': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1360a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col =  df_full_data['y']\n",
    "df_full_data = df_full_data.drop(columns=['y'])\n",
    "df_full_data['y']=y_col\n",
    "df_full_data = df_full_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fbf4ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_full_data, 'df_full_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e334c49f",
   "metadata": {},
   "source": [
    "## @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a38e419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_data = load_dataframe('df_full_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "04eea608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50800_flag</th>\n",
       "      <th>50801_flag</th>\n",
       "      <th>50802_flag</th>\n",
       "      <th>50803_flag</th>\n",
       "      <th>50804_flag</th>\n",
       "      <th>50805_flag</th>\n",
       "      <th>50806_flag</th>\n",
       "      <th>50808_flag</th>\n",
       "      <th>50809_flag</th>\n",
       "      <th>50810_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnicity_HISPANIC/LATINO - HONDURAN</th>\n",
       "      <th>ethnicity_OTHER</th>\n",
       "      <th>ethnicity_SOUTH AMERICAN</th>\n",
       "      <th>ethnicity_UNKNOWN/NOT SPECIFIED</th>\n",
       "      <th>ethnicity_WHITE</th>\n",
       "      <th>ethnicity_WHITE - EASTERN EUROPEAN</th>\n",
       "      <th>ethnicity_nan</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_nan</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4407</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4411</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4412 rows × 460 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      50800_flag  50801_flag  50802_flag  50803_flag  50804_flag  50805_flag  \\\n",
       "0             -1           0          -1           0          -1          -1   \n",
       "1              0           0           0           0           0           0   \n",
       "2             -1           0          -1           0          -1           0   \n",
       "3              0           0           0           0           0           0   \n",
       "4             -1          -1          -1          -1          -1           0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "4407           0           0          -1           0          -1           0   \n",
       "4408           0          -1          -1           0          -1           0   \n",
       "4409          -1           0          -1           0           1           0   \n",
       "4410           0           0          -1           0          -1           0   \n",
       "4411           0          -1          -1           0          -1           0   \n",
       "\n",
       "      50806_flag  50808_flag  50809_flag  50810_flag  ...  \\\n",
       "0              1          -1           1          -1  ...   \n",
       "1              0           0           0           0  ...   \n",
       "2              0          -1           1          -1  ...   \n",
       "3              0           0           0           0  ...   \n",
       "4             -1          -1           1          -1  ...   \n",
       "...          ...         ...         ...         ...  ...   \n",
       "4407           0          -1           0          -1  ...   \n",
       "4408           0           0           0           0  ...   \n",
       "4409          -1           1           1          -1  ...   \n",
       "4410           0           0           0           0  ...   \n",
       "4411           1           1           0           0  ...   \n",
       "\n",
       "      ethnicity_HISPANIC/LATINO - HONDURAN  ethnicity_OTHER  \\\n",
       "0                                        0                0   \n",
       "1                                        0                0   \n",
       "2                                        0                0   \n",
       "3                                        0                0   \n",
       "4                                        0                0   \n",
       "...                                    ...              ...   \n",
       "4407                                     0                0   \n",
       "4408                                     0                0   \n",
       "4409                                     0                0   \n",
       "4410                                     0                0   \n",
       "4411                                     0                0   \n",
       "\n",
       "      ethnicity_SOUTH AMERICAN  ethnicity_UNKNOWN/NOT SPECIFIED  \\\n",
       "0                            0                                0   \n",
       "1                            0                                0   \n",
       "2                            0                                0   \n",
       "3                            0                                1   \n",
       "4                            0                                0   \n",
       "...                        ...                              ...   \n",
       "4407                         0                                0   \n",
       "4408                         0                                0   \n",
       "4409                         0                                1   \n",
       "4410                         0                                0   \n",
       "4411                         0                                0   \n",
       "\n",
       "      ethnicity_WHITE  ethnicity_WHITE - EASTERN EUROPEAN  ethnicity_nan  \\\n",
       "0                   1                                   0              0   \n",
       "1                   1                                   0              0   \n",
       "2                   1                                   0              0   \n",
       "3                   0                                   0              0   \n",
       "4                   1                                   0              0   \n",
       "...               ...                                 ...            ...   \n",
       "4407                1                                   0              0   \n",
       "4408                1                                   0              0   \n",
       "4409                0                                   0              0   \n",
       "4410                1                                   0              0   \n",
       "4411                0                                   0              0   \n",
       "\n",
       "      gender_M  gender_nan  y  \n",
       "0            1           0  0  \n",
       "1            0           0  0  \n",
       "2            0           0  0  \n",
       "3            0           0  1  \n",
       "4            1           0  0  \n",
       "...        ...         ... ..  \n",
       "4407         1           0  0  \n",
       "4408         1           0  0  \n",
       "4409         1           0  0  \n",
       "4410         1           0  0  \n",
       "4411         1           0  0  \n",
       "\n",
       "[4412 rows x 460 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d42ede",
   "metadata": {},
   "source": [
    "## export to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "907c4ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata = df_full_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd1464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "627904bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a file\n",
    "np.save('data/fulldata.npy', fulldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "26133d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "fulldata = np.load('data/fulldata.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3cecf1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4412, 720)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ee0b1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "labdata = np.load('data/labdata.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "82d2ecbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0475698 ,  0.0212766 , -0.5       , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.114788  ,  0.12765957, -0.5       , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.05274043,  0.        , -0.5       , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.04550155,  0.        , -0.5       , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.00620476, -0.0212766 , -0.5       , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.00620476, -0.0212766 , -0.5       , ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c5914b",
   "metadata": {},
   "source": [
    "## Test on a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d628eb",
   "metadata": {},
   "source": [
    "before cleaning the dataset, check with an XGBoost that can handle missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e264b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'observation_window_hours': 6, 'antibiotics_name': ['CEFTAZIDIME'], 'bacteria_ids': [80004, 80026, 80005, 80017, 80040, 80008, 80007, 80002], 'negative_to_positive_ratio': 2, 'test_set_fraction': 0.01, 'validation_set_fraction': 0.29, 'train_set_fraction': 0.8, 'random_state': 11}\n",
      "Train count: Counter({0: 2598, 1: 534})\n",
      "Validate count: Counter({0: 1062, 1: 218})\n",
      "0.1703125\n",
      "Train shape: (3132, 719)\n",
      "Validate shape: (1280, 719)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_validate, learning_curve\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "params.validation_set_fraction=0.29\n",
    "params.test_set_fraction=0.01\n",
    "params.negative_to_positive_ratio=2\n",
    "print(params.__dict__)\n",
    "df_X = df_full_data.drop(columns = ['y'] )\n",
    "df_y = df_full_data[['y']]\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(df_X, df_y, stratify=df_y, test_size=0.29, random_state=params.random_state)\n",
    "print(f\"Train count: {Counter(y_train['y'])}\")\n",
    "print(f\"Validate count: {Counter(y_validate['y'])}\")\n",
    "# X_train = train_set.drop(columns=['y'])\n",
    "# y_train = train_set['y'].astype('int')\n",
    "# X_validate = df_validation.drop(columns=['y'])\n",
    "# y_validate = df_validation['y'].astype('int')\n",
    "print(np.mean(y_validate['y']))\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Validate shape: {X_validate.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56a906f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions mean: 0.04609375\n",
      "simple_score: 0.81796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: 4.63 (+/- 0.15)\n",
      "score_time: 0.03 (+/- 0.01)\n",
      "test_roc_auc: 0.67 (+/- 0.04)\n",
      "test_accuracy: 0.81 (+/- 0.01)\n",
      "test_precision: 0.33 (+/- 0.10)\n",
      "test_recall: 0.12 (+/- 0.04)\n",
      "test_f1: 0.18 (+/- 0.05)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      1062\n",
      "           1       0.37      0.10      0.16       218\n",
      "\n",
      "    accuracy                           0.82      1280\n",
      "   macro avg       0.61      0.53      0.53      1280\n",
      "weighted avg       0.76      0.82      0.77      1280\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    }
   ],
   "source": [
    "def print_accuracy(cv_scores):\n",
    "    # print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))\n",
    "    for score_name, scores in cv_scores.items():\n",
    "        print(\"%s: %0.2f (+/- %0.2f)\" % (score_name, scores.mean(), scores.std() * 2))\n",
    "        \n",
    "def train_xgboost():\n",
    "    import xgboost as xgb\n",
    "\n",
    "    param_dist = dict(objective='binary:logistic',\n",
    "                      n_estimators=100, # 170,\n",
    "                      eval_metric='rmsle', # 'logloss',\n",
    "                      max_depth=4,\n",
    "                      eta=0.3,\n",
    "                      booster='gbtree',\n",
    "                      n_jobs=4,\n",
    "#                       enable_categorical=True\n",
    "                      # subsample=0.8,\n",
    "                      # colsample_bynode=0.5\n",
    "                    )\n",
    "\n",
    "    xgboost_cls = xgb.XGBClassifier(**param_dist)\n",
    "    xgboost_cls.fit(X_train, y_train)\n",
    "    return xgboost_cls\n",
    "\n",
    "\n",
    "# model = train_random_forest()\n",
    "model = train_xgboost()\n",
    "y_validate_hat = model.predict(X_validate)\n",
    "print(f\"predictions mean: {np.mean(y_validate_hat)}\")\n",
    "simple_score = model.score(X_validate, y_validate)\n",
    "print(f\"simple_score: {simple_score}\")\n",
    "# scoring = {'AUC': 'roc_auc', 'Accuracy': 'accuracy', 'Precision': 'precision', 'Recall': 'recall'}\n",
    "\n",
    "scoring = ['roc_auc','accuracy','precision', 'recall', 'f1']\n",
    "cv_scores = cross_validate(model, X_train, y_train['y'], scoring=scoring)\n",
    "print_accuracy(cv_scores)\n",
    "print(classification_report(y_validate, y_validate_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c385e444",
   "metadata": {},
   "source": [
    "Import cohort/labels data from the .pkl file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33daf4c5",
   "metadata": {},
   "source": [
    "## Tools to explore too many unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c87390",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_unprocessed[categorical_cols].nunique().sort_values(ascending=False)[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b916de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "allvals = df_dataset_unprocessed['50911'].unique().tolist()\n",
    "len(allvals), df_dataset_unprocessed['50911'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_unprocessed['50911'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "68a2a3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261c55ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in allvals if x and not x == np.nan and not str(x).replace('.','').isnumeric()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04747c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([float(x) for x in allvals if x and str(x).replace('.','').isnumeric()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bbd442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_unprocessed.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d30358",
   "metadata": {},
   "source": [
    "## THE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f0be0bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.1'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee43ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "322fa648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0475698 ,  0.0212766 , -0.5       , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.114788  ,  0.12765957, -0.5       , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.05274043,  0.        , -0.5       , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.04550155,  0.        , -0.5       , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.00620476, -0.0212766 , -0.5       , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.00620476, -0.0212766 , -0.5       , ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123767c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
