{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q PyAthena"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-twist",
   "metadata": {},
   "source": [
    "## Prepare Datasets for Predictor Training, Validation and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-liberia",
   "metadata": {},
   "source": [
    "#### TS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-beast",
   "metadata": {},
   "source": [
    "Import modules that build patient cohort, extract demographics and lab events data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distinguished-williams",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataproc.cohort import query_esbl_pts, remove_dups, observation_window\n",
    "from dataproc.sampling import generate_samples\n",
    "from dataproc.roc_auc_curves import plt_roc_auc_curve, plt_precision_recall_curve\n",
    "from dataproc.sampling import stratify_set\n",
    "from dataproc.create_dataset import dataset_creation\n",
    "from hyper_params import HyperParams\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "future-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hyperparams instance\n",
    "params = HyperParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-career",
   "metadata": {},
   "source": [
    "Patients cohort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "electronic-steps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3894\n",
       "1     742\n",
       "Name: RESISTANT_YN, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select esbl microbiology test\n",
    "esbl_admits = query_esbl_pts()\n",
    "# Remove dups\n",
    "esbl_admits = remove_dups(esbl_admits)\n",
    "# Create observation window\n",
    "esbl_admits_window = observation_window(esbl_admits, window_size=params.observation_window_hours)\n",
    "# Subset columns\n",
    "pts_labels = esbl_admits_window[['hadm_id', 'index_date','RESISTANT_YN']]\n",
    "pts_labels.to_pickle('data/patient_labels.pkl')\n",
    "pts_labels['RESISTANT_YN'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-volume",
   "metadata": {},
   "source": [
    "Import cohort/labels data from the .pkl file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quantitative-stations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4636, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>index_date</th>\n",
       "      <th>RESISTANT_YN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14564</th>\n",
       "      <td>101757</td>\n",
       "      <td>2132-12-31 16:30:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14608</th>\n",
       "      <td>186474</td>\n",
       "      <td>2155-02-25 18:45:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14612</th>\n",
       "      <td>194730</td>\n",
       "      <td>2170-12-22 06:12:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14625</th>\n",
       "      <td>112086</td>\n",
       "      <td>2147-04-05 14:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14634</th>\n",
       "      <td>158569</td>\n",
       "      <td>2142-04-01 18:34:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hadm_id          index_date  RESISTANT_YN\n",
       "14564   101757 2132-12-31 16:30:00             0\n",
       "14608   186474 2155-02-25 18:45:00             1\n",
       "14612   194730 2170-12-22 06:12:00             0\n",
       "14625   112086 2147-04-05 14:00:00             1\n",
       "14634   158569 2142-04-01 18:34:00             1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts_labels = pd.read_pickle('data/patient_labels_multiple.pkl')\n",
    "print(pts_labels.shape)\n",
    "pts_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-temperature",
   "metadata": {},
   "source": [
    "Patient's features data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the features\n",
    "features = dataset_creation(pts_labels['hadm_id'], params.observation_window_hours)\n",
    "features = features.merge(pts_labels[['hadm_id','RESISTANT_YN']], on='hadm_id')\n",
    "features.to_pickle('data/features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-luxembourg",
   "metadata": {},
   "source": [
    "Import features data from the .pkl file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle('data/features.pkl')\n",
    "print(list(features.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "loinc_codes = list(features.drop(columns=['hadm_id', 'subject_id', 'admittime','admission_type']).columns)[:-8]\n",
    "print(list(loinc_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_summary = features[loinc_codes].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding the features\n",
    "from dataproc.embeddings import loinc_values\n",
    "\n",
    "loinc_vals = loinc_values(loinc_codes)\n",
    "loinc_vals.dropna(subset=['value'], inplace=True)\n",
    "loinc_vals = loinc_vals.astype({'value': 'string', 'loinc_code': 'category'})\n",
    "loinc_vals['value'] = loinc_vals['value'].map(lambda x: x.lstrip('LESS THAN '))\n",
    "loinc_vals['value'] = loinc_vals['value'].map(lambda x: x.lstrip('GREATER THAN '))\n",
    "loinc_vals['value'] = loinc_vals['value'].map(lambda x: x.lstrip('>GREATER THAN '))\n",
    "loinc_vals['value'] = loinc_vals['value'].map(lambda x: x.lstrip('<LESS THAN '))\n",
    "loinc_vals['value'] = loinc_vals['value'].map(lambda x: x.rstrip(' NG/ML'))\n",
    "loinc_vals['value'] = loinc_vals['value'].map(lambda x: x.lstrip('<>'))\n",
    "loinc_vals['value'] = loinc_vals['value'].map(lambda x: x.replace(',', '.'))\n",
    "loinc_vals.drop(list(loinc_vals.loc[loinc_vals['value'] == 'UNABLE TO ANALYZE'].index),  inplace=True)\n",
    "loinc_vals.drop(list(loinc_vals.loc[loinc_vals['value'] == 'MOLYSIS FALSELY DECREASES THIS RESULT'].index),  inplace=True)\n",
    "loinc_vals.drop(list(loinc_vals.loc[loinc_vals['value'] == 'COMPUTER NETWORK FAILURE. TEST NOT RESULTED.'].index),  inplace=True)\n",
    "loinc_vals.drop(list(loinc_vals.loc[loinc_vals['value'] == 'UNABLE TO DETERMINE'].index),  inplace=True)\n",
    "loinc_vals.drop(list(loinc_vals.loc[loinc_vals['value'] == ':UNABLE TO DETERMINE'].index),  inplace=True)\n",
    "loinc_vals.drop(list(loinc_vals.loc[loinc_vals['value'] == 'UNABLE TO QUANTITATE'].index),  inplace=True)\n",
    "loinc_vals.drop(list(loinc_vals.loc[loinc_vals['value'] == 'UNABLE TO REPORT'].index),  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = []\n",
    "categorical = []\n",
    "weird = []\n",
    "for code in loinc_codes:\n",
    "    size = len(loinc_vals.loc[loinc_vals['loinc_code'] == str(code), 'value'])\n",
    "    size_unique = len(loinc_vals.loc[loinc_vals['loinc_code'] == str(code), 'value'].unique())\n",
    "    sum_na = pd.to_numeric(loinc_vals.loc[loinc_vals['loinc_code'] == str(code), 'value'], errors='coerce').isna().sum()\n",
    "    if sum_na / size < 0.05:\n",
    "        numeric.append(code)\n",
    "    elif sum_na / size > 0.05 and size_unique < 100:\n",
    "        categorical.append(code)\n",
    "    else:\n",
    "        weird.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove lab column that contains only 'inf' and 'Nan'\n",
    "numeric.remove('26498-6')\n",
    "# remove lab column that contains phrase 'See comments'\n",
    "categorical.remove('33914-3')\n",
    "# remove lab column that contains phrase 'Random'\n",
    "categorical.remove('13362-9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All:', len(loinc_codes))\n",
    "print('Numeric: ', len(numeric))\n",
    "print('Categorical: ', len(categorical))\n",
    "print('Weird:', len(weird))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-lighter",
   "metadata": {},
   "source": [
    "Summary statistics for numeric lab codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_stats = []\n",
    "for code in numeric:\n",
    "    a = pd.to_numeric(loinc_vals.loc[loinc_vals['loinc_code'] == str(code), 'value'], errors='coerce').describe()\n",
    "    numeric_stats.append(a)\n",
    "numeric_stats_df = pd.concat(numeric_stats, axis=1, keys=numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now, ignoring the mixed type lab tests\n",
    "dataset = features.drop(columns=weird, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-bulgaria",
   "metadata": {},
   "source": [
    "### Data Preprocessing  and Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(dataset.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-quebec",
   "metadata": {},
   "source": [
    "#### Clean lab numeric variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric selected columns\n",
    "dataset[numeric] = dataset[numeric].apply(pd.to_numeric, errors='coerce', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-ancient",
   "metadata": {},
   "source": [
    "Since many lab data have outliers the median and interquartile range can be used to standardizing the numeric variables:   \n",
    "- value = (value – median) / (p75 – p25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanardize_numeric_values(df, list_of_clms, ref_df):\n",
    "    \"\"\"\n",
    "    Use the median and interquartile range to \n",
    "    standardize the numeric variables\n",
    "    value = (value – median) / (p75 – p25)\n",
    "    \"\"\"\n",
    "    for code in list_of_clms:\n",
    "        median = ref_df[code]['50%']\n",
    "        p25 = ref_df[code]['25%']\n",
    "        p75 = ref_df[code]['75%']\n",
    "        df[code] = (df[code] - median) / (p75 - p25)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stanardize_numeric_values(dataset, numeric, numeric_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-nerve",
   "metadata": {},
   "source": [
    "Imputation of missing values using scikit-learn https://scikit-learn.org/stable/modules/impute.html#impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def replace_missing_val(df, list_of_clms, how='median'):\n",
    "    \"\"\"\n",
    "    Imputation of missing values using median\n",
    "    \"\"\"\n",
    "    imp = SimpleImputer(strategy=how)\n",
    "    df_prc = imp.fit_transform(df[list_of_clms])\n",
    "    df = pd.DataFrame(df_prc, columns=list_of_clms)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "numlabvars_df = replace_missing_val(dataset, numeric, how='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "numlabvars_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-visibility",
   "metadata": {},
   "source": [
    "#### Clean lab categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['30089-7'] = np.where(dataset['30089-7'].isin(['<1','1','2']), '0-2',\n",
    "                     np.where(dataset['30089-7'].isin(['3','4']),'3-5', dataset['30089-7']))\n",
    "\n",
    "dataset['5767-9'] = np.where(dataset['5767-9'].isin(['CLEAR']), 'Clear',\n",
    "                    np.where(dataset['5767-9'].isin(['SLHAZY']), 'SlHazy',\n",
    "                    np.where(dataset['5767-9'].isin(['HAZY']), 'Hazy',\n",
    "                    np.where(dataset['5767-9'].isin(['SlCloudy']),'SlCldy',  \n",
    "                    np.where(dataset['5767-9'].isin(['CLOUDY']),'Cloudy',dataset['5767-9'])))))\n",
    "\n",
    "dataset['5769-5'] = np.where(dataset['5769-5'].isin(['0']), 'NEG',\n",
    "                    np.where(dataset['5769-5'].isin(['NOTDONE']), 'NONE',\n",
    "                    np.where(dataset['5769-5'].isin(['LRG']), 'MANY', dataset['5769-5'])))\n",
    "\n",
    "dataset['5778-6'] = np.where(dataset['5778-6'].isin(['YELLOW','YEL']), 'Yellow',\n",
    "                    np.where(dataset['5778-6'].isin(['STRAW']), 'Straw',\n",
    "                    np.where(dataset['5778-6'].isin(['AMBER','AMB']), 'Amber', \n",
    "                    np.where(dataset['5778-6'].isin(['RED']), 'Red', \n",
    "                    np.where(dataset['5778-6'].isin(['ORANGE']), 'Orange', \n",
    "                    np.where(dataset['5778-6'].isin(['DKAMB','DKAMBER']), 'DkAmb', \n",
    "                    np.where(dataset['5778-6'].isin([' ']), np.nan, dataset['5778-6'])))))))\n",
    "\n",
    "dataset['5797-6'] = np.where(dataset['5797-6'].isin(['>80']), '80',dataset['5797-6'])\n",
    "\n",
    "dataset['5804-0'] = np.where(dataset['5804-0'].isin(['>300']), '300',\n",
    "                    np.where(dataset['5804-0'].isin([' ']), np.nan, dataset['5804-0']))\n",
    "\n",
    "dataset['5818-0'] = np.where(dataset['5818-0'].isin(['.2']), '0.2',\n",
    "                    np.where(dataset['5818-0'].isin(['>8','>8.0']), '8',\n",
    "                    np.where(dataset['5818-0'].isin(['>12']), '12',\n",
    "                    np.where(dataset['5818-0'].isin(['NotDone']), np.nan, dataset['5818-0']))))\n",
    "\n",
    "dataset['5822-2'] = np.where(dataset['5822-2'].isin(['0', 'N']), 'NONE',\n",
    "                    np.where(dataset['5822-2'].isin(['NOTDONE']), np.nan, dataset['5822-2']))\n",
    "\n",
    "dataset['778-1'] = np.where(dataset['778-1'].isin(['UNABLE TO ESTIMATE DUE TO PLATELET CLUMPS']), 'NOTDETECTED', dataset['778-1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print value counts for each lab categorical variable:\n",
    "for col in categorical:\n",
    "    print('----------------------------------')\n",
    "    print('Column name: ', col)\n",
    "    print(dataset[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 'Nan' values in categorical variables by 'UNKNOWN'\n",
    "dataset.update(dataset[categorical].fillna('UNKNOWN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[categorical].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-garlic",
   "metadata": {},
   "source": [
    "Use one hot encoder for categoric lab features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(dataset[categorical])\n",
    "enc.categories_[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehotlabvars = enc.transform(dataset[categorical]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotlabvars_df = pd.get_dummies(dataset[categorical])\n",
    "print(onehotlabvars_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-margin",
   "metadata": {},
   "source": [
    "To reduce the correlation among variables, remove one feature column from the one-hot encoded array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = list(onehotlabvars_df.filter(regex='_UNKNOWN'))\n",
    "onehotlabvars_df = onehotlabvars_df[onehotlabvars_df.columns.drop(col_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotlabvars_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-colorado",
   "metadata": {},
   "source": [
    "#### Clean demographic static variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "staticvars = ['admission_type', 'admission_location', 'insurance', 'language', \n",
    "               'religion', 'marital_status', 'ethnicity', 'gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['admission_location'] = \\\n",
    "np.where(dataset['admission_location'].isin(['** INFO NOT AVAILABLE **']), 'EMERGENCY ROOM ADMIT',\n",
    "np.where(dataset['admission_location'].isin(['TRANSFER FROM SKILLED NUR','TRANSFER FROM OTHER HEALT',\n",
    "                        'TRANSFER FROM HOSP/EXTRAM']), 'TRANSFER FROM MED FACILITY',dataset['admission_location']))\n",
    "dataset['language'] = \\\n",
    "np.where(~dataset['language'].isin(['ENGL','SPAN']),'OTHER',dataset['language'])\n",
    "\n",
    "dataset['religion'] = \\\n",
    "np.where(~dataset['religion'].isin(['CATHOLIC','NOT SPECIFIED','UNOBTAINABLE','PROTESTANT QUAKER','JEWISH']),'OTHER',\n",
    "np.where(dataset['religion'].isin(['UNOBTAINABLE']),'NOT SPECIFIED', dataset['religion'] ))\n",
    "\n",
    "dataset['ethnicity'] = \\\n",
    "np.where(dataset['ethnicity'].isin(['ASIAN - CHINESE',\n",
    "                                    'ASIAN - ASIAN INDIAN',\n",
    "                                    'ASIAN - VIETNAMESE',\n",
    "                                    'ASIAN - OTHER',\n",
    "                                    'ASIAN - FILIPINO',\n",
    "                                    'ASIAN - CAMBODIAN']), 'ASIAN',\n",
    "np.where(dataset['ethnicity'].isin(['WHITE - RUSSIAN',\n",
    "                                    'WHITE - BRAZILIAN',\n",
    "                                    'WHITE - OTHER EUROPEAN']),'WHITE',\n",
    "np.where(dataset['ethnicity'].isin(['BLACK/CAPE VERDEAN',\n",
    "                                    'BLACK/HAITIAN',\n",
    "                                    'BLACK/AFRICAN']), 'BLACK/AFRICAN AMERICAN',\n",
    "np.where(dataset['ethnicity'].isin(['HISPANIC/LATINO - PUERTO RICAN',\n",
    "                                   'HISPANIC/LATINO - DOMINICAN',\n",
    "                                   'HISPANIC/LATINO - SALVADORAN',\n",
    "                                   'HISPANIC/LATINO - CUBAN',\n",
    "                                   'HISPANIC/LATINO - MEXICAN']), 'HISPANIC OR LATINO',   \n",
    "np.where(dataset['ethnicity'].isin(['MULTI RACE ETHNICITY',\n",
    "                                    'MIDDLE EASTERN',\n",
    "                                    'PORTUGUESE',\n",
    "                                    'AMERICAN INDIAN/ALASKA NATIVE',\n",
    "                                    'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER',\n",
    "                                    'AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE']), 'OTHER',\n",
    "np.where(dataset['ethnicity'].isin(['UNABLE TO OBTAIN',\n",
    "                                    'PATIENT DECLINED TO ANSWER']), 'UNKNOWN/NOT SPECIFIED',\n",
    "dataset['ethnicity']))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print value counts for each demographic variable:\n",
    "for col in staticvars:\n",
    "    print('----------------------------------')\n",
    "    print('Column name: ', col)\n",
    "    print(dataset[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-distributor",
   "metadata": {},
   "source": [
    "#### Use one hot encoder for demographic features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(dataset[staticvars])\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehotstaticvars = enc.transform(dataset[staticvars]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotstaticvars_df = pd.get_dummies(dataset[staticvars])\n",
    "print(onehotstaticvars_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-iceland",
   "metadata": {},
   "source": [
    "To reduce the correlation among variables, remove one feature column from the one-hot encoded array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['admission_type_URGENT', 'admission_location_TRANSFER FROM MED FACILITY', \n",
    "            'insurance_Self Pay', 'language_OTHER', 'religion_NOT SPECIFIED', 'marital_status_UNKNOWN (DEFAULT)',\n",
    "            'ethnicity_UNKNOWN/NOT SPECIFIED', 'gender_M']\n",
    "onehotstaticvars_df = onehotstaticvars_df[onehotstaticvars_df.columns.drop(col_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotstaticvars_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-class",
   "metadata": {},
   "source": [
    "#### Combine all features and constract full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response variable\n",
    "#response = np.array([dataset['RESISTANT_YN']])\n",
    "#response = response.T\n",
    "#response.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last variable is a target variable \n",
    "#fulldata = np.concatenate((numlabvars_df, onehotlabvars_df, onehotstaticvars_df, response), axis=1)\n",
    "#fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numlabvars_df.shape, onehotlabvars_df.shape, onehotstaticvars_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata = pd.concat([numlabvars_df, onehotlabvars_df, onehotstaticvars_df, dataset['RESISTANT_YN']], axis=1)\n",
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a file\n",
    "#np.save('data/fulldata.npy', fulldata)\n",
    "fulldata.to_csv('data/fulldata.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "#fulldata = np.load('data/fulldata.npy')\n",
    "fulldata = pd.read_csv('data/fulldata.csv')\n",
    "#fulldata = pd.read_csv('data/fulldata_multiple.csv')\n",
    "fulldata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-chapter",
   "metadata": {},
   "source": [
    "### Machine Learning Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "score_f1 = make_scorer(f1_score, average='weighted')\n",
    "score_pr = make_scorer(precision_score, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "y = fulldata['RESISTANT_YN']\n",
    "X = fulldata.drop(columns=['RESISTANT_YN'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "# summarize class distribution\n",
    "print(Counter(y))\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample minority class\n",
    "oversample = RandomOverSampler(sampling_strategy = 'minority')\n",
    "# fit and apply the transform\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample majority class\n",
    "undersample = RandomUnderSampler(sampling_strategy = 0.5)\n",
    "# fit and apply the transform\n",
    "X_under, y_under = undersample.fit_resample(X_train, y_train)\n",
    "print(Counter(y_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "original_cnt = Counter(y_train)\n",
    "oversmpl_cnt = Counter(y_over)\n",
    "\n",
    "d = {'training set': ['original','original','oversampled','oversampled'],\n",
    "     'class': [0,1,0,1], \n",
    "     'count': [original_cnt[0] , original_cnt[1], oversmpl_cnt[0], oversmpl_cnt[1]]}\n",
    "df = pd.DataFrame(data=d)\n",
    " \n",
    "# who v/s fare barplot\n",
    "sns.barplot(x = 'training set', y = 'count', hue='class', data = df)\n",
    "\n",
    " \n",
    "# Show the plot\n",
    "plt.title('Original vs. Oversampled Training Set')\n",
    "plt.ylim([0, 4000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-minute",
   "metadata": {},
   "source": [
    "Learning curve plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve as function of sample size\n",
    "pipe_forest = make_pipeline(RandomForestClassifier(random_state=RANDOM_STATE, \n",
    "                               class_weight='balanced_subsample',\n",
    "                               n_estimators=150,\n",
    "                               max_depth=20,\n",
    "                               max_leaf_nodes=70,\n",
    "                               max_features=40,\n",
    "                               max_samples=0.9,\n",
    "                               min_samples_leaf=2,\n",
    "                               min_samples_split=10))\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_forest,\n",
    "                              X=X_over,\n",
    "                              y=y_over,\n",
    "                              train_sizes = np.linspace(0.1, 1.0, 5),\n",
    "                              scoring=score_f1,   \n",
    "                              cv=3)\n",
    "train_mean= np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean= np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training')\n",
    "plt.fill_between(train_sizes, train_mean+train_std, train_mean-train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='orange', linestyle='--', marker='s', markersize=5, label='test')\n",
    "plt.fill_between(train_sizes, test_mean+test_std, test_mean-test_std, alpha=0.15, color='orange')\n",
    "plt.grid()\n",
    "plt.xlabel('Sample size')\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-fitness",
   "metadata": {},
   "source": [
    "Validation curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change on of the hyperparameters\n",
    "pipe_forest = make_pipeline(RandomForestClassifier(random_state=RANDOM_STATE, \n",
    "                                                   class_weight='balanced_subsample',\n",
    "                                                   n_estimators=150,\n",
    "                                                   max_depth=20,\n",
    "                                                   max_leaf_nodes=70,\n",
    "                                                   max_features=40,\n",
    "                                                   max_samples=0.9,\n",
    "                                                   min_samples_leaf=2,\n",
    "                                                   min_samples_split=10))\n",
    "# Set parameter range\n",
    "param_name = 'max_leaf_nodes'\n",
    "param_range = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "train_scores, test_scores = \\\n",
    "                validation_curve(estimator=pipe_forest,\n",
    "                              X=X_over,\n",
    "                              y=y_over,\n",
    "                              param_name='randomforestclassifier__'+param_name,\n",
    "                              param_range =param_range,\n",
    "                              scoring=score_f1,   \n",
    "                              cv=3)\n",
    "train_mean= np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean= np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(param_range, train_mean, color='blue', marker='o', markersize=5, label='training')\n",
    "plt.fill_between(param_range, train_mean+train_std, train_mean-train_std, alpha=0.15, color='blue')\n",
    "plt.plot(param_range, test_mean, color='orange', linestyle='--', marker='s', markersize=5, label='test')\n",
    "plt.fill_between(param_range, test_mean+test_std, test_mean-test_std, alpha=0.15, color='orange')\n",
    "plt.grid()\n",
    "plt.xlabel(param_name)\n",
    "plt.ylabel('F1-Score')\n",
    "plt.title('Validation Curve: ' + param_name)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-director",
   "metadata": {},
   "source": [
    "Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator = RandomForestClassifier(random_state=RANDOM_STATE, \n",
    "                               class_weight='balanced_subsample', n_estimators=100),\n",
    "                  param_grid={'max_depth': [10, 20, 30],\n",
    "                             'max_leaf_nodes': [30, 50, 70],\n",
    "                             'max_features': [20, 40, 60],\n",
    "                             'max_samples': [0.7, 0.9],\n",
    "                             'min_samples_leaf':[2, 5, 7, 10],\n",
    "                             'min_samples_split':[5, 10, 15]},\n",
    "                  scoring = score_pr,\n",
    "                  cv=2)\n",
    "\n",
    "gs = gs.fit(X_over, y_over)\n",
    "print(gs.best_params_)\n",
    "#scores = cross_val_score(gs, X_over, y_over, scoring=score_pr, cv=2)\n",
    "#print('CV precision: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-hayes",
   "metadata": {},
   "source": [
    "Random Forest Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=RANDOM_STATE, \n",
    "                               class_weight='balanced_subsample',\n",
    "                               n_estimators=100,\n",
    "                               max_depth=10,\n",
    "                               max_leaf_nodes=90,\n",
    "                               max_features=20,\n",
    "                               max_samples=0.9,\n",
    "                               min_samples_leaf=5,\n",
    "                               min_samples_split=10)\n",
    "# Train model\n",
    "forest.fit(X_train, y_train)\n",
    "# Prediction\n",
    "y_true, y_pred = y_test, forest.predict(X_test)\n",
    "# Classification report (recall, preccision, f-score, accuracy):\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "print('TN:',tn, 'FP:',fp, 'FN:',fn, 'TP:',tp )\n",
    "print()\n",
    "scores = cross_val_score(forest, X_train, y_train, scoring=score_f1, cv=5)\n",
    "print('CV F1-score: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain Model for after sampled test set\n",
    "forest = RandomForestClassifier(random_state=RANDOM_STATE, \n",
    "                               class_weight='balanced_subsample',\n",
    "                               n_estimators=150,\n",
    "                               max_depth=20,\n",
    "                               max_leaf_nodes=70,\n",
    "                               max_features=40,\n",
    "                               max_samples=0.9,\n",
    "                               min_samples_leaf=2,\n",
    "                               min_samples_split=10)\n",
    "\n",
    "# Train model\n",
    "forest.fit(X_over, y_over)\n",
    "# Prediction\n",
    "y_true, y_pred = y_test, forest.predict(X_test)\n",
    "# Classification report (recall, preccision, f-score, accuracy)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "print('TN:',tn, 'FP:',fp, 'FN:',fn, 'TP:',tp )\n",
    "print()\n",
    "scores = cross_val_score(forest, X_train, y_train, scoring=score_f1, cv=5)\n",
    "print('CV F1-score: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n",
    "# ROC_AUC curve\n",
    "print()\n",
    "plt_roc_auc_curve(forest, X_test, y_test, model_name='Random Forest')\n",
    "# Precision_Recall curve\n",
    "print()\n",
    "plt_precision_recall_curve(forest, X_test, y_test, model_name='Random Forest')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save classification report\n",
    "clsf_report = pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv('rand_forest_summary_report.csv', index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-works",
   "metadata": {},
   "source": [
    "#### Ensemble Learning:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- k-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(penalty='l2', C=0.0001, random_state=RANDOM_STATE, max_iter=8000)\n",
    "clf2 = RandomForestClassifier(random_state=RANDOM_STATE, \n",
    "                               class_weight='balanced_subsample',\n",
    "                               n_estimators=150,\n",
    "                               max_depth=20,\n",
    "                               max_leaf_nodes=70,\n",
    "                               max_features=40,\n",
    "                               max_samples=0.9,\n",
    "                               min_samples_leaf=2,\n",
    "                               min_samples_split=10)\n",
    "clf3 = KNeighborsClassifier(n_neighbors=10, p=2, metric='minkowski')\n",
    "\n",
    "clf_labels = ['Logistic Reg', 'Random Forest', 'KNN']\n",
    "for clf, label in zip([clf1, clf2, clf3], clf_labels):\n",
    "    scores = cross_val_score(estimator = clf,\n",
    "                            X=X_over,\n",
    "                            y=y_over,\n",
    "                            cv=5,\n",
    "                            scoring=score_f1)\n",
    "    print('f-1 score:', scores.mean(), scores.std(), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[\n",
    "         ('lr', clf1), ('rf', clf2), ('knn', clf3)], voting='hard')\n",
    "eclf = eclf.fit(X_over, y_over)\n",
    "# Prediction\n",
    "y_true, y_pred = y_test, eclf.predict(X_test)\n",
    "# Classification report (recall, preccision, f-score, accuracy)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "print('TN:',tn, 'FP:',fp, 'FN:',fn, 'TP:',tp )\n",
    "print()\n",
    "scores = cross_val_score(forest, X_train, y_train, scoring=score_f1, cv=5)\n",
    "print('CV F1-score: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-niagara",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
